{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with Open CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you will learn how to do fundamental things with open cv, with respect to the given project of a squat analysis. We will need to: \n",
    "\n",
    " + acess a camera\n",
    " + read an image/video from it\n",
    " + find markes in the respective frames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always we need to import some packages so we can use their methods/functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check whether Opven CV was imported correctly, we check the version of Open CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV-Python Version 4.12.0\n"
     ]
    }
   ],
   "source": [
    "print(\"OpenCV-Python Version {}\".format(cv2.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Acessing The Camera\n",
    "\n",
    "As we need to see an athlete doing a squat, we need a camera. So let's check which camera devices are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A camera was opened\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "else:\n",
    "    print(\"A camera was opened\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Read A Frame From The Camera\n",
    "\n",
    "As a camera was opened we would like to get an image from it. We do this using Open CV's method .read() on the camera object cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, frame = cap.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to show the frame so we know what we have recorded. We use the .imshow() method of Open CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('This is the recorded frame', frame)\n",
    "\n",
    "# warte bis 'q' gedrückt wird\n",
    "while True:\n",
    "    # 1 ms warten, Events verarbeiten\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Find Markers\n",
    "\n",
    "As we would like to find markers at some point we need to define the markers properties first. There are several options available starting from color markers over infrared to patternbased ones. ArUco Markers are a classic marker type for this kind of tracking. Therefore we will go with them. What is an ArUco Code and what can we do with it? Well. Let's create an ArUco code on our own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ArUco codes often come in form of a dictionary. A 6x6 ArUco code has 6 rows and 6 columns with either black or white cells. The dictionary contains all available versions that respect the ArUco code boundary conditions. We can load such a dictionary by using Open CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a next step we want to use one of the markers in the dictionary. Of course, we want to use the number 42 as our index. Our reference image for the marker is 200. \n",
    "\n",
    "Source: geeksforgeeks.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Generate a marker\n",
    "marker_id = 42\n",
    "marker_size = 200  # Size in pixels\n",
    "marker_image = cv2.aruco.generateImageMarker(aruco_dict, marker_id, marker_size)\n",
    "\n",
    "cv2.imwrite('marker_42.png', marker_image)\n",
    "plt.imshow(marker_image, cmap='gray', interpolation='nearest')\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.title(f'ArUco Marker {marker_id}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's create a new frame that contains an ArUco code that we can try to find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, frame = cap.read()\n",
    "cv2.imshow('This is the recorded frame', frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting ArUco markers involves several steps:\n",
    "\n",
    "+ Loading the Image: Load the image containing the ArUco marker using OpenCV’s imread function.\n",
    "+ Converting to Grayscale: Convert the image to grayscale to enhance the detection process.\n",
    "+ Detecting Markers: Use the detectMarkers function from the cv2.aruco module to detect the markers in the image.\n",
    "\n",
    "Source: geeksforgeeks.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected markers: [[42]\n",
      " [40]\n",
      " [41]\n",
      " [38]\n",
      " [39]]\n"
     ]
    }
   ],
   "source": [
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)\n",
    "parameters = cv2.aruco.DetectorParameters()\n",
    "\n",
    "# Create the ArUco detector\n",
    "detector = cv2.aruco.ArucoDetector(aruco_dict, parameters)\n",
    "# Detect the markers\n",
    "corners, ids, rejected = detector.detectMarkers(gray)\n",
    "# Print the detected markers\n",
    "print(\"Detected markers:\", ids)\n",
    "if ids is not None:\n",
    "    cv2.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "    cv2.imshow('Detected Markers', frame)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first steps were carried out in this notebook to be able to detect an ArUco code and therefore we have the base for a squat analysis. Check out https://www.geeksforgeeks.org/detecting-aruco-markers-with-opencv-and-python-1/\n",
    "for details about pose estimation with ArUco Codes and camera calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
